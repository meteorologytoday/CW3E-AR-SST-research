import numpy as np
#import fmon_tools, watertime_tools
import anomalies
import ARstat_tool
import xarray as xr
import watertime_tools
import traceback
from pathlib import Path
import argparse
from datetime import (timedelta, datetime, timezone)

parser = argparse.ArgumentParser(
                    prog = 'plot_skill',
                    description = 'Plot prediction skill of GFS on AR.',
)

parser.add_argument('--input-dir', type=str, help='Input file', required=True)
parser.add_argument('--beg-year', type=int, help='Input file', required=True)
parser.add_argument('--end-year', type=int, help='Input file', required=True)

parser.add_argument('--output-dir', type=str, help='Output dir', default="")
parser.add_argument('--title', type=str, help='Output title', default="")
parser.add_argument('--no-display', action="store_true")
args = parser.parse_args()
print(args)

if args.output_dir == "":
    args.output_dir = args.input_dir

print("Planned output dir: %s" % (args.output_dir,))

yrs = list(range(args.beg_year, args.end_year+1))

ds = ARstat_tool.loadDatasets(args.input_dir, yrs)

MLG_frc = (ds['MLG_frc_sw'] + ds['MLG_frc_lw'] + ds['MLG_frc_sh']  + ds['MLG_frc_lh'] + ds['MLG_frc_fwf'] + ds['MLG_rescale']).rename('MLG_frc')
MLG_adv = (ds['MLG_hadv'] + ds['MLG_vadv']).rename('MLG_adv')
MLG_diff = (ds['MLG_vdiff'] + ds['MLG_hdiff']).rename('MLG_diff')
MLG_nonfrc = (MLG_adv + MLG_diff + ds['MLG_ent']).rename('MLG_nonfrc')

ds = xr.merge(
    [
        ds,
        MLG_frc,
        MLG_nonfrc,
        MLG_adv,
        MLG_diff,
    ]
)

# Compute mean and anomaly
def convertdt64todt(dt64):
    return datetime.fromtimestamp( (dt64 - np.datetime64("1970-01-01")) / np.timedelta64(1, 's' ))
 
ts_np64 = ds.time.to_numpy().astype("datetime64[ns]")
ts_dt   = ts_np64.astype("datetime64[s]").astype(object) # need to be datetime64[s] first so that the object casting will result in a datetime object.


tm_np64 = np.array([ np.datetime64('2022-01-01') + np.timedelta64(1,'D') * d for d in range(365) ]).astype("datetime64[ns]")


ds_mean = []
ds_anom = []

target_varnames = ["IVT", "dMLTdt", "MLG_frc", "MLG_nonfrc"]
#varnames = ds.keys()
for _, varname in enumerate(target_varnames):

    print("Doing statistics of ", varname)
    
    _da_mean = xr.DataArray(
        name = varname,
        data = np.zeros((len(tm_np64), len(ds.coords["lat"]), len(ds.coords["lon"]))),
        dims = ["time", "lat", "lon"],
        coords = {
            "time" : tm_np64,
        }
    )
    
    _da_anom = xr.DataArray(
        name = varname,
        data = np.zeros((len(ts_np64), len(ds.coords["lat"]), len(ds.coords["lon"]))),
        dims = ["time", "lat", "lon"],
        coords = {
            "time" : ts_np64,
        }
    )
    
    for i in range(len(ds.coords["lon"])):
        for j in range(len(ds.coords["lat"])):
            
            _var = ds[varname][:, j, i]

            xs = _var.to_numpy()
            
            tm, xm, xa, cnt = anomalies.decomposeClimAnom(ts_dt, xs)

            _da_mean[:, j, i] = xm
            _da_anom[:, j, i] = xa


    ds_anom.append(_da_anom)
    ds_mean.append(_da_mean)


ds_anom = xr.merge(ds_anom)
ds_mean = xr.merge(ds_mean)


ds_anom.to_netcdf("testtt.nc")

# Construct
t_months = np.arange(1, 7)

ds_stats = {}

for condition_name, (IVT_min, IVT_max) in [
    ("clim",  (0, np.inf)),
    ("ARf",   (0, 250)),
    ("AR",    (250, np.inf)),
    ("AR+ARf",    (None, None)),
]:

    print("Process condition: ", condition_name)

    _tmp = {}
    for varname, _ in ds_anom.items():
        _tmp[varname] = (["time", "lat", "lon", "stat"], np.zeros((len(t_months), len(ds.coords["lat"]), len(ds.coords["lon"]), 2)) )

    ds_stat = xr.Dataset(
        _tmp,

        coords = {
            "time" : t_months,
            "lat"  : ds.coords["lat"],
            "lon"  : ds.coords["lon"],
            "stat" : ["mean", "std"]
        }
    )

    ds_stats[condition_name] = ds_stat


    for i in range(len(ds.coords["lon"])):
        for j in range(len(ds.coords["lat"])):

            print("Process point: (%d, %d)" % (j, i)) 
            _ds_subset      = []
            _ds_anom_subset = []
            _ds_mean_subset = []
            
            _ds_subset = [
                ds[varname][:, j, i] for _, varname in enumerate(ds_mean.keys())
            ]

            _ds_anom_subset = [
                ds_anom[varname][:, j, i] for _, varname in enumerate(ds_mean.keys())
            ]

            _ds_mean_subset = [
                ds_mean[varname][:, j, i] for _, varname in enumerate(ds_mean.keys())
            ]

            _ds_subset = xr.merge(_ds_subset)
            _ds_anom_subset = xr.merge(_ds_anom_subset)
            _ds_mean_subset = xr.merge(_ds_mean_subset)

            for t, m in enumerate(t_months): 
                
                if condition_name == "clim":
                    _ds_ref = _ds_subset
                    _cond = _ds_ref.time.dt.month.isin(watertime_tools.wm2m(m))
         
                elif condition_name == "AR+ARf":
                    _ds_ref = _ds_anom_subset
                    _cond = _ds_ref.time.dt.month.isin(watertime_tools.wm2m(m))
                
                elif condition_name in ["AR", "ARf"]:
                    _ds_ref = _ds_anom_subset
                    _cond = (
                          ( _ds_subset.IVT >= IVT_min ) 
                        & ( _ds_subset.IVT <  IVT_max ) 
                        & _ds_ref.time.dt.month.isin(watertime_tools.wm2m(m))
                    )
           
                else:
                    raise Exception("Unknown condition_name: ", condition_name) 

                print("Conditon %s : cnt = %d, wm = %d" % (condition_name, np.sum(_cond), m))

                _ds = _ds_ref.where(_cond)
                #_ds = _ds_ref
                    
                for varname, _ in ds_stat.items():

                    _data = _ds[varname] * 1e6
                    ds_stat[varname][t, j, i, 0] = np.nanmean(_data)
                    ds_stat[varname][t, j, i, 1] = np.nanstd(_data)
                    

ds_stats["AR-ARf"] = ds_stats["AR"] - ds_stats["ARf"]

for k in ["clim", "AR", "ARf", "AR+ARf"]:
    output_filename = "%s/stat_%s.nc" % (args.output_dir, k,)
    print("Writing output file: %s" % (output_filename,))
    
    ds_stats[k].to_netcdf(output_filename)

